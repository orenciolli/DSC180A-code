{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8544df74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import spacy\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9eef39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.tsv', delimiter='\\t', header = None)\n",
    "\n",
    "df.rename({0: 'id', 1: 'label', 2: 'statement', 3: 'subject', 4: 'speaker', 5: 'job-title',\n",
    "           6: 'state_info', 7: 'party_affiliation', 8: 'barely_true_counts', 9: 'false_counts',\n",
    "           10: 'half_true_counts', 11: 'mostly_true_counts', 12: 'pants_on_fire_counts', 13: 'context'\n",
    "          }, axis = 1, inplace = True)\n",
    "\n",
    "mapping = {'false': 0, 'half-true': 1, 'mostly-true': 2, 'true': 3, 'barely-true': 4,\n",
    "       'pants-fire': 5}\n",
    "\n",
    "df['label'] = df['label'].replace(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179229b9",
   "metadata": {},
   "source": [
    "# Data engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fc38508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_party(val):\n",
    "    \n",
    "    left = {'democrat', 'green', 'democratic-farmer-labor', 'ocean-state-tea-party-action'}\n",
    "    right = {'republican', 'libertarian', 'tea-party-member', 'Moderate',\n",
    "       'constitution-party'}\n",
    "    \n",
    "    center_none = {'none', 'organization', 'independent',\n",
    "       'columnist', 'activist', 'talk-show-host',\n",
    "       'newsmaker', 'journalist', 'labor-leader', 'state-official',\n",
    "       'business-leader', 'education-official', 'tea-party-member', np.NaN,\n",
    "       'liberal-party-canada', 'government-body', 'Moderate',\n",
    "       }\n",
    "    \n",
    "    if val in left:\n",
    "        return 0\n",
    "    elif val in center_none:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "df['party_affiliation'] = df['party_affiliation'].apply(clean_party)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9cf84a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['subject'] = label_encoder.fit_transform(df['subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fa3f143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    return (blob.sentiment.polarity + 1) / 2\n",
    "\n",
    "df['sentiment'] = df['statement'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e3ebd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ociolli/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#removing stop words, neglecting casing\n",
    "\n",
    "df['statement'] = df['statement'].str.lower()\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download the stopwords dataset\n",
    "nltk.download('stopwords')\n",
    "def remove_stopwords(sentence):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    filtered_sentence = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_sentence)\n",
    "\n",
    "df['statement_cleaned'] = df['statement'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7416965c",
   "metadata": {},
   "source": [
    "# Glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55419f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_880/609049260.py:11: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_file, word2vec_file)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "\n",
    "# Path to the downloaded GloVe embeddings file\n",
    "glove_file = 'glove.6B.100d.txt'\n",
    "\n",
    "word2vec_file = 'glove.6B.100d.word2vec'  # Any path and filename you prefer\n",
    "\n",
    "# Convert GloVe format to Word2Vec format\n",
    "glove2word2vec(glove_file, word2vec_file)\n",
    "\n",
    "# Load the Word2Vec model\n",
    "glove_model = KeyedVectors.load_word2vec_format(word2vec_file, binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ef5a8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_embedding(sentence, model, dim=100):\n",
    "    # Tokenize the sentence into words\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    \n",
    "    # Filter out words that are not in the model's vocabulary\n",
    "    words_in_vocab = [word for word in words if word in model.key_to_index]\n",
    "    \n",
    "    # Check if there are words in the sentence that are in the model's vocabulary\n",
    "    if words_in_vocab:\n",
    "        # Compute the mean of word embeddings for the words in the sentence\n",
    "        embedding = sum(model[word] for word in words_in_vocab) / len(words_in_vocab)\n",
    "        return embedding\n",
    "    else:\n",
    "        # If none of the words in the sentence are in the model's vocabulary, return None\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c5c846e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['glove'] = df['statement_cleaned'].apply(lambda x: sentence_embedding(x, glove_model))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524a0465",
   "metadata": {},
   "source": [
    "# Credibility score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d311dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_880/2228308207.py:17: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cs_lookup[speaker] = cs / (MTC + HTC + BTC + FC + PFC)\n"
     ]
    }
   ],
   "source": [
    "cs_lookup = {}\n",
    "\n",
    "for speaker in set(df['speaker'].unique()) - {np.nan}:\n",
    "    try:\n",
    "        limited = df[df['speaker'] == speaker]\n",
    "        vals = limited.iloc[0]\n",
    "       \n",
    "        MTC = vals.loc['mostly_true_counts']\n",
    "        HTC = vals.loc['half_true_counts']\n",
    "        BTC = vals.loc['barely_true_counts']\n",
    "        FC = vals.loc['false_counts']\n",
    "        PFC = vals.loc['pants_on_fire_counts']\n",
    "\n",
    "        #exclude true counts = weight 0\n",
    "        cs = (0.2 * MTC) + (0.5 * HTC) + (0.75 * BTC) + (0.9 * FC) + (1 * PFC)\n",
    "\n",
    "        cs_lookup[speaker] = cs / (MTC + HTC + BTC + FC + PFC)\n",
    "        \n",
    "    except:\n",
    "        print(speaker)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ab653d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_cs = np.nanmean(list(cs_lookup.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2a326f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in cs_lookup.items():\n",
    "    if np.isnan(val):\n",
    "        cs_lookup[key] = mean_cs\n",
    "    else: continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "de6bfc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_cred(val):\n",
    "    if not isinstance(val, str) or (val not in cs_lookup.keys()):\n",
    "        return mean_cs\n",
    "\n",
    "    else:\n",
    "        return cs_lookup[val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2004111f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['credibility'] = df['speaker'].apply(impute_cred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4c3eb8",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad0236ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('cuda')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e4538c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment, party_affiliation (subject later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76c0c56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class seqModel(nn.Module):\n",
    "    def __init__(self, hidden_size=128, num_classes=6):\n",
    "        super(seqModel, self).__init__()\n",
    "        \n",
    "        self.lstm = torch.nn.LSTM(100, hidden_size)\n",
    "        self.dropout = torch.nn.Dropout(p = 0.15)\n",
    "        self.state_fc = nn.Linear(hidden_size, 64)\n",
    "\n",
    "        self.feature_fc = nn.Linear(3, 64)\n",
    "\n",
    "        self.combined_fc = nn.Linear(128, 6)\n",
    "\n",
    "            \n",
    "    def forward(self, input_seq, party_affiliation, credibility, sentiment):\n",
    "        \n",
    "        # statement branch\n",
    "        statement_out, _ = self.lstm(input_seq)\n",
    "#         statement_out = statement_out[:, -1, :]\n",
    "        statement_out = self.dropout(statement_out)\n",
    "        statement_out = F.relu(self.state_fc(statement_out))\n",
    "        statement_out = self.dropout(statement_out)\n",
    "\n",
    "        # feature branch\n",
    "        feature_vec = torch.cat([party_affiliation.unsqueeze(1),\n",
    "                                 credibility.unsqueeze(1), sentiment.unsqueeze(1)], dim = 1)\n",
    "        \n",
    "        feature_out = F.relu(self.feature_fc(feature_vec))\n",
    "\n",
    "        combined = torch.cat([statement_out, feature_out], dim = 1)\n",
    "        combined = self.combined_fc(combined)\n",
    "\n",
    "        return F.softmax(combined, dim = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2a7b0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.labels = torch.tensor(df['label'].values, dtype=torch.long)\n",
    "        self.glove_embeddings = torch.stack([torch.tensor(embedding) for embedding in df['glove']], dim=0)\n",
    "        self.party_affiliation = torch.tensor(df['party_affiliation'].values, dtype=torch.long)\n",
    "        self.credibility = torch.tensor(df['credibility'].values, dtype=torch.float)\n",
    "        self.sentiment = torch.tensor(df['sentiment'].values, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'label': self.labels[idx],\n",
    "            'glove_embedding': self.glove_embeddings[idx],\n",
    "            'party_affiliation': self.party_affiliation[idx],\n",
    "            'credibility': self.credibility[idx],\n",
    "            'sentiment': self.sentiment[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9102cbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = CustomDataset(train_df)\n",
    "val_dataset = CustomDataset(val_df)\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ab8c81",
   "metadata": {},
   "source": [
    "# Training and eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fa0e284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = seqModel()\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ad598276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Validation Accuracy: 0.2290\n",
      "Epoch 2/30, Validation Accuracy: 0.2607\n",
      "Epoch 3/30, Validation Accuracy: 0.2729\n",
      "Epoch 4/30, Validation Accuracy: 0.2856\n",
      "Epoch 5/30, Validation Accuracy: 0.2988\n",
      "Epoch 6/30, Validation Accuracy: 0.3120\n",
      "Epoch 7/30, Validation Accuracy: 0.2969\n",
      "Epoch 8/30, Validation Accuracy: 0.3091\n",
      "Epoch 9/30, Validation Accuracy: 0.3052\n",
      "Epoch 10/30, Validation Accuracy: 0.3262\n",
      "Epoch 11/30, Validation Accuracy: 0.3286\n",
      "Epoch 12/30, Validation Accuracy: 0.3325\n",
      "Epoch 13/30, Validation Accuracy: 0.3159\n",
      "Epoch 14/30, Validation Accuracy: 0.3306\n",
      "Epoch 15/30, Validation Accuracy: 0.3291\n",
      "Epoch 16/30, Validation Accuracy: 0.3267\n",
      "Epoch 17/30, Validation Accuracy: 0.3252\n",
      "Epoch 18/30, Validation Accuracy: 0.3174\n",
      "Epoch 19/30, Validation Accuracy: 0.3242\n",
      "Epoch 20/30, Validation Accuracy: 0.3262\n",
      "Epoch 21/30, Validation Accuracy: 0.3291\n",
      "Epoch 22/30, Validation Accuracy: 0.3271\n",
      "Epoch 23/30, Validation Accuracy: 0.3306\n",
      "Epoch 24/30, Validation Accuracy: 0.3247\n",
      "Epoch 25/30, Validation Accuracy: 0.3301\n",
      "Epoch 26/30, Validation Accuracy: 0.3320\n",
      "Epoch 27/30, Validation Accuracy: 0.3271\n",
      "Epoch 28/30, Validation Accuracy: 0.3301\n",
      "Epoch 29/30, Validation Accuracy: 0.3315\n",
      "Epoch 30/30, Validation Accuracy: 0.3369\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 30\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    for batch in train_data_loader:\n",
    "        # Move data to device\n",
    "        for key in batch:\n",
    "            batch[key] = batch[key].to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(batch['glove_embedding'], batch['party_affiliation'],\n",
    "                       batch['credibility'], batch['sentiment'])\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(output, batch['label'])\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = []\n",
    "        val_labels = []\n",
    "\n",
    "        for val_batch in val_data_loader:\n",
    "            # Move data to device\n",
    "            for key in val_batch:\n",
    "                val_batch[key] = val_batch[key].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            val_output = model(val_batch['glove_embedding'], val_batch['party_affiliation'],\n",
    "                               val_batch['credibility'], val_batch['sentiment'])\n",
    "            val_outputs.append(val_output)\n",
    "            val_labels.append(val_batch['label'])\n",
    "\n",
    "        val_outputs = torch.cat(val_outputs, dim=0)\n",
    "        val_labels = torch.cat(val_labels, dim=0)\n",
    "\n",
    "        # Calculate validation accuracy\n",
    "        _, predicted = torch.max(val_outputs, 1)\n",
    "        val_accuracy = accuracy_score(val_labels.cpu().numpy(), predicted.cpu().numpy())\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9abd59a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32421875\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_outputs = []\n",
    "    val_labels = []\n",
    "\n",
    "    for val_batch in val_data_loader:\n",
    "        # Move data to device\n",
    "        for key in val_batch:\n",
    "            val_batch[key] = val_batch[key].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        val_output = model(val_batch['glove_embedding'], val_batch['party_affiliation'],\n",
    "                           val_batch['credibility'], val_batch['sentiment'])\n",
    "        val_outputs.append(val_output)\n",
    "        val_labels.append(val_batch['label'])\n",
    "\n",
    "    val_outputs = torch.cat(val_outputs, dim=0)\n",
    "    val_labels = torch.cat(val_labels, dim=0)\n",
    "\n",
    "    # Calculate validation accuracy\n",
    "    _, predicted = torch.max(val_outputs, 1)\n",
    "    val_accuracy = accuracy_score(val_labels.cpu().numpy(), predicted.cpu().numpy())\n",
    "    print(val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4fa431",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2a4569fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.tsv', delimiter='\\t', header = None)\n",
    "\n",
    "test.rename({0: 'id', 1: 'label', 2: 'statement', 3: 'subject', 4: 'speaker', 5: 'job-title',\n",
    "           6: 'state_info', 7: 'party_affiliation', 8: 'barely_true_counts', 9: 'false_counts',\n",
    "           10: 'half_true_counts', 11: 'mostly_true_counts', 12: 'pants_on_fire_counts', 13: 'context'\n",
    "          }, axis = 1, inplace = True)\n",
    "\n",
    "mapping = {'false': 0, 'half-true': 1, 'mostly-true': 2, 'true': 3, 'barely-true': 4,\n",
    "       'pants-fire': 5}\n",
    "\n",
    "test['label'] = test['label'].replace(mapping)\n",
    "\n",
    "\n",
    "test['party_affiliation'] = test['party_affiliation'].apply(clean_party)\n",
    "#test['subject'] = label_encoder.fit_transform(test['subject'])\n",
    "test['credibility'] = test['speaker'].apply(impute_cred)\n",
    "test['sentiment'] = test['statement'].apply(get_sentiment)\n",
    "\n",
    "test['statement'] = test['statement'].str.lower()\n",
    "test['statement_cleaned'] = test['statement'].apply(remove_stopwords)\n",
    "test['glove'] = test['statement_cleaned'].apply(lambda x: sentence_embedding(x, glove_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3cd2439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(test)\n",
    "\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4c824ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.287292817679558\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = []\n",
    "    test_labels = []\n",
    "\n",
    "    for test_batch in test_data_loader:\n",
    "        # Move data to device\n",
    "        for key in test_batch:\n",
    "            test_batch[key] = test_batch[key].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        test_output = model(test_batch['glove_embedding'], test_batch['party_affiliation'],\n",
    "                           test_batch['credibility'], test_batch['sentiment'])\n",
    "        test_outputs.append(test_output)\n",
    "        test_labels.append(test_batch['label'])\n",
    "\n",
    "    test_outputs = torch.cat(test_outputs, dim=0)\n",
    "    test_labels = torch.cat(test_labels, dim=0)\n",
    "\n",
    "    # Calculate validation accuracy\n",
    "    _, predicted = torch.max(test_outputs, 1)\n",
    "    test_accuracy = accuracy_score(test_labels.cpu().numpy(), predicted.cpu().numpy())\n",
    "    print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d226957",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
