{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44ebae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59021e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.tsv', delimiter='\\t', header = None)\n",
    "\n",
    "df.rename({0: 'id', 1: 'label', 2: 'statement', 3: 'subject', 4: 'speaker', 5: 'job-title',\n",
    "           6: 'state_info', 7: 'party_affiliation', 8: 'barely_true_counts', 9: 'false_counts',\n",
    "           10: 'half_true_counts', 11: 'mostly_true_counts', 12: 'pants_on_fire_counts', 13: 'context'\n",
    "          }, axis = 1, inplace = True)\n",
    "\n",
    "mapping = {'false': 0, 'half-true': 1, 'mostly-true': 2, 'true': 3, 'barely-true': 4,\n",
    "       'pants-fire': 5}\n",
    "\n",
    "df['label'] = df['label'].replace(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8aaa5e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_party(val):\n",
    "    \n",
    "    left = {'democrat', 'green', 'democratic-farmer-labor', 'ocean-state-tea-party-action'}\n",
    "    right = {'republican', 'libertarian', 'tea-party-member', 'Moderate',\n",
    "       'constitution-party'}\n",
    "    \n",
    "    center_none = {'none', 'organization', 'independent',\n",
    "       'columnist', 'activist', 'talk-show-host',\n",
    "       'newsmaker', 'journalist', 'labor-leader', 'state-official',\n",
    "       'business-leader', 'education-official', 'tea-party-member', np.NaN,\n",
    "       'liberal-party-canada', 'government-body', 'Moderate',\n",
    "       }\n",
    "    \n",
    "    if val in left:\n",
    "        return 0\n",
    "    elif val in center_none:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "df['party_affiliation'] = df['party_affiliation'].apply(clean_party)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33b0a07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['subject'] = label_encoder.fit_transform(df['subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7db8aa35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print('cuda')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48ba665",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24cd8f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "class ClaimDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=128):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        statement = self.data['statement'].iloc[idx]\n",
    "        political_affiliation = self.data['party_affiliation'].iloc[idx]\n",
    "        subject_encoded = self.data['subject_encoded'].iloc[idx]\n",
    "        label = self.data['label'].iloc[idx]\n",
    "\n",
    "        # Tokenize and encode text input with attention mask\n",
    "        inputs = self.tokenizer(\n",
    "            statement,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_statement': inputs['input_ids'].squeeze(),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),\n",
    "            'input_political_affiliation': torch.tensor(political_affiliation, dtype=torch.float),\n",
    "            'input_subject': torch.tensor(subject_encoded, dtype=torch.float),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "max_length = 128  # Adjust as needed\n",
    "claim_dataset = ClaimDataset(df, tokenizer, max_length)\n",
    "\n",
    "# Split the dataset into train, validation, and test sets\n",
    "train_size = int(0.8 * len(claim_dataset))\n",
    "val_size = (len(claim_dataset) - train_size) // 2\n",
    "test_size = len(claim_dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(claim_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Create DataLoader instances\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f9701b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define the model\n",
    "class ClaimClassifier(nn.Module):\n",
    "    def __init__(self, hidden_size=768, num_classes=6):\n",
    "        super(ClaimClassifier, self).__init__()\n",
    "        self.bert_model = bert_model\n",
    "        self.fc_statement = nn.Linear(hidden_size, num_classes)\n",
    "        self.fc_political_affiliation = nn.Linear(1, 1)\n",
    "        self.fc_subject = nn.Linear(1, 1)\n",
    "        self.fc_final = nn.Linear(8, num_classes)\n",
    "\n",
    "    def forward(self, input_statement, attention_mask, input_political_affiliation, input_subject):\n",
    "        # Tokenize and encode inputs\n",
    "        pooled_output = self.bert_model(input_statement, attention_mask=attention_mask).pooler_output\n",
    "        \n",
    "        # Apply linear layers to numerical features\n",
    "        fc_statement_output = self.fc_statement(pooled_output)\n",
    "        fc_political_affiliation_output = self.fc_political_affiliation(input_political_affiliation.view(-1, 1))\n",
    "        fc_subject_output = self.fc_subject(input_subject.view(-1, 1))\n",
    "\n",
    "        # Concatenate or add numerical features\n",
    "        merged_inputs = torch.cat([fc_statement_output, fc_political_affiliation_output, fc_subject_output], dim=1)\n",
    "\n",
    "        # Apply final linear layer\n",
    "        output = self.fc_final(merged_inputs)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d61fedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the model\n",
    "model = ClaimClassifier().to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d06b0b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Training Loss: 12.3582, Validation Loss: 8.3129, Accuracy: 0.1943\n",
      "Epoch 2/3, Training Loss: 6.8971, Validation Loss: 6.6724, Accuracy: 0.2109\n",
      "Epoch 3/3, Training Loss: 5.4039, Validation Loss: 5.0233, Accuracy: 0.1797\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 3\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        input_statement = batch['input_statement'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        input_political_affiliation = batch['input_political_affiliation'].to(device)\n",
    "        input_subject = batch['input_subject'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(input_statement, attention_mask, input_political_affiliation, input_subject)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Calculate average training loss\n",
    "    average_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_batch in val_loader:\n",
    "            val_input_statement = val_batch['input_statement'].to(device)\n",
    "            val_attention_mask = batch['attention_mask'].to(device)\n",
    "            val_input_political_affiliation = val_batch['input_political_affiliation'].to(device)\n",
    "            val_input_subject = val_batch['input_subject'].to(device)\n",
    "            val_labels = val_batch['label'].to(device)\n",
    "\n",
    "            val_outputs = model(val_input_statement, val_attention_mask, val_input_political_affiliation, val_input_subject)\n",
    "            val_loss += criterion(val_outputs, val_labels).item()\n",
    "\n",
    "            # Calculate the number of correct predictions\n",
    "            _, predicted = torch.max(val_outputs, 1)\n",
    "            correct_predictions += (predicted == val_labels).sum().item()\n",
    "\n",
    "    # Calculate average validation loss\n",
    "    average_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_predictions / len(val_dataset)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Training Loss: {average_train_loss:.4f}, Validation Loss: {average_val_loss:.4f}, Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1231b9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "with torch.no_grad():\n",
    "        for val_batch in test_loader:\n",
    "            val_input_statement = val_batch['input_statement'].to(device)\n",
    "            val_attention_mask = batch['attention_mask'].to(device)\n",
    "            val_input_political_affiliation = val_batch['input_political_affiliation'].to(device)\n",
    "            val_input_subject = val_batch['input_subject'].to(device)\n",
    "            val_labels = val_batch['label'].to(device)\n",
    "\n",
    "            val_outputs = model(val_input_statement, val_attention_mask, val_input_political_affiliation, val_input_subject)\n",
    "            val_loss += criterion(val_outputs, val_labels).item()\n",
    "\n",
    "            # Calculate the number of correct predictions\n",
    "            _, predicted = torch.max(val_outputs, 1)\n",
    "            correct_predictions += (predicted == val_labels).sum().item()\n",
    "\n",
    "        # Calculate average validation loss\n",
    "        average_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = correct_predictions / len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c56f4a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3876953125"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7676ea3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
