{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "883d6f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import spacy\n",
    "from textblob import TextBlob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d6e136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.tsv', delimiter='\\t', header = None)\n",
    "\n",
    "df.rename({0: 'id', 1: 'label', 2: 'statement', 3: 'subject', 4: 'speaker', 5: 'job-title',\n",
    "           6: 'state_info', 7: 'party_affiliation', 8: 'barely_true_counts', 9: 'false_counts',\n",
    "           10: 'half_true_counts', 11: 'mostly_true_counts', 12: 'pants_on_fire_counts', 13: 'context'\n",
    "          }, axis = 1, inplace = True)\n",
    "\n",
    "mapping = {'false': 0, 'half-true': 1, 'mostly-true': 2, 'true': 3, 'barely-true': 4,\n",
    "       'pants-fire': 5}\n",
    "\n",
    "df['label'] = df['label'].replace(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4c87a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_party(val):\n",
    "    \n",
    "    left = {'democrat', 'green', 'democratic-farmer-labor', 'ocean-state-tea-party-action'}\n",
    "    right = {'republican', 'libertarian', 'tea-party-member', 'Moderate',\n",
    "       'constitution-party'}\n",
    "    \n",
    "    center_none = {'none', 'organization', 'independent',\n",
    "       'columnist', 'activist', 'talk-show-host',\n",
    "       'newsmaker', 'journalist', 'labor-leader', 'state-official',\n",
    "       'business-leader', 'education-official', 'tea-party-member', np.NaN,\n",
    "       'liberal-party-canada', 'government-body', 'Moderate',\n",
    "       }\n",
    "    \n",
    "    if val in left:\n",
    "        return 0\n",
    "    elif val in center_none:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "df['party_affiliation'] = df['party_affiliation'].apply(clean_party)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ada21ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['subject'] = label_encoder.fit_transform(df['subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6961f11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    return (blob.sentiment.polarity + 1) / 2\n",
    "\n",
    "df['sentiment'] = df['statement'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0af82ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print('cuda')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e045e7",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b9d85d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "class ClaimDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=128):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        statement = self.data['statement'].iloc[idx]\n",
    "        political_affiliation = self.data['party_affiliation'].iloc[idx]\n",
    "        subject_encoded = self.data['subject_encoded'].iloc[idx]\n",
    "        label = self.data['label'].iloc[idx]\n",
    "        sentiment = self.data['sentiment'].iloc[idx]\n",
    "\n",
    "        # Tokenize and encode text input with attention mask\n",
    "        inputs = self.tokenizer(\n",
    "            statement,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_statement': inputs['input_ids'].squeeze(),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),\n",
    "            'input_political_affiliation': torch.tensor(political_affiliation, dtype=torch.float),\n",
    "            'input_subject': torch.tensor(subject_encoded, dtype=torch.float),\n",
    "            'input_sentiment': torch.tensor(sentiment, dtype=torch.float),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "            \n",
    "        }\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "max_length = 128  # Adjust as needed\n",
    "claim_dataset = ClaimDataset(df, tokenizer, max_length)\n",
    "\n",
    "# Split the dataset into train, validation, and test sets\n",
    "train_size = int(0.8 * len(claim_dataset))\n",
    "val_size = (len(claim_dataset) - train_size) // 2\n",
    "test_size = len(claim_dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(claim_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Create DataLoader instances\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "31d4bf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define the model\n",
    "class ClaimClassifier(nn.Module):\n",
    "    def __init__(self, hidden_size=768, num_classes=6):\n",
    "        super(ClaimClassifier, self).__init__()\n",
    "        self.bert_model = bert_model\n",
    "        self.fc_statement = nn.Linear(hidden_size, num_classes)\n",
    "        self.fc_political_affiliation = nn.Linear(1, 1)\n",
    "        self.fc_sentiment = nn.Linear(1, 1)\n",
    "        self.fc_subject = nn.Linear(1, 1)\n",
    "        self.fc_final = nn.Linear(9, num_classes)\n",
    "\n",
    "    def forward(self, input_statement, attention_mask, input_political_affiliation, input_subject, input_sentiment):\n",
    "        # Tokenize and encode inputs\n",
    "        pooled_output = self.bert_model(input_statement, attention_mask=attention_mask).pooler_output\n",
    "        \n",
    "        # Apply linear layers to numerical features\n",
    "        fc_statement_output = self.fc_statement(pooled_output)\n",
    "        fc_political_affiliation_output = self.fc_political_affiliation(input_political_affiliation.view(-1, 1))\n",
    "        fc_subject_output = self.fc_subject(input_subject.view(-1, 1))\n",
    "        fc_sentiment_output = self.fc_subject(input_sentiment.view(-1, 1))\n",
    "\n",
    "        # Concatenate or add numerical features\n",
    "        merged_inputs = torch.cat([fc_statement_output, fc_political_affiliation_output, \n",
    "                                   fc_subject_output, fc_sentiment_output], dim=1)\n",
    "\n",
    "        # Apply final linear layer\n",
    "        output = self.fc_final(merged_inputs)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0cc2b757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the model\n",
    "model = ClaimClassifier().to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e9778c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Training Loss: 132.1845, Validation Loss: 21.2329, Accuracy: 0.2295\n",
      "Epoch 2/3, Training Loss: 10.2368, Validation Loss: 3.4089, Accuracy: 0.1729\n",
      "Epoch 3/3, Training Loss: 2.0646, Validation Loss: 1.9041, Accuracy: 0.2070\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 3\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        input_statement = batch['input_statement'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        input_political_affiliation = batch['input_political_affiliation'].to(device)\n",
    "        input_subject = batch['input_subject'].to(device)\n",
    "        input_sentiment = batch['input_sentiment'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(input_statement, attention_mask, input_political_affiliation, \n",
    "                       input_subject, input_sentiment)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Calculate average training loss\n",
    "    average_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_batch in val_loader:\n",
    "            val_input_statement = val_batch['input_statement'].to(device)\n",
    "            val_attention_mask = batch['attention_mask'].to(device)\n",
    "            val_input_political_affiliation = val_batch['input_political_affiliation'].to(device)\n",
    "            val_input_subject = val_batch['input_subject'].to(device)\n",
    "            val_input_sentiment = batch['input_sentiment'].to(device)\n",
    "            val_labels = val_batch['label'].to(device)\n",
    "\n",
    "            val_outputs = model(val_input_statement, val_attention_mask, val_input_political_affiliation, \n",
    "                                val_input_subject, val_input_sentiment)\n",
    "            val_loss += criterion(val_outputs, val_labels).item()\n",
    "\n",
    "            # Calculate the number of correct predictions\n",
    "            _, predicted = torch.max(val_outputs, 1)\n",
    "            correct_predictions += (predicted == val_labels).sum().item()\n",
    "\n",
    "    # Calculate average validation loss\n",
    "    average_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_predictions / len(val_dataset)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Training Loss: {average_train_loss:.4f}, Validation Loss: {average_val_loss:.4f}, Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "daa4fdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "correct_predictions = 0\n",
    "with torch.no_grad():\n",
    "        for val_batch in test_loader:\n",
    "            val_input_statement = val_batch['input_statement'].to(device)\n",
    "            val_attention_mask = batch['attention_mask'].to(device)\n",
    "            val_input_political_affiliation = val_batch['input_political_affiliation'].to(device)\n",
    "            val_input_subject = val_batch['input_subject'].to(device)\n",
    "            val_input_sentiment = batch['input_sentiment'].to(device)\n",
    "            val_labels = val_batch['label'].to(device)\n",
    "\n",
    "            val_outputs = model(val_input_statement, val_attention_mask, val_input_political_affiliation, \n",
    "                                val_input_subject, val_input_sentiment)\n",
    "            val_loss += criterion(val_outputs, val_labels).item()\n",
    "\n",
    "            # Calculate the number of correct predictions\n",
    "            _, predicted = torch.max(val_outputs, 1)\n",
    "            correct_predictions += (predicted == val_labels).sum().item()\n",
    "\n",
    "        # Calculate average validation loss\n",
    "        average_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = correct_predictions / len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a926f5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2177734375"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346f0159",
   "metadata": {},
   "source": [
    "# Evaluation on train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9e1f2872",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.tsv', delimiter='\\t', header = None)\n",
    "\n",
    "test.rename({0: 'id', 1: 'label', 2: 'statement', 3: 'subject', 4: 'speaker', 5: 'job-title',\n",
    "           6: 'state_info', 7: 'party_affiliation', 8: 'barely_true_counts', 9: 'false_counts',\n",
    "           10: 'half_true_counts', 11: 'mostly_true_counts', 12: 'pants_on_fire_counts', 13: 'context'\n",
    "          }, axis = 1, inplace = True)\n",
    "\n",
    "mapping = {'false': 0, 'half-true': 1, 'mostly-true': 2, 'true': 3, 'barely-true': 4,\n",
    "       'pants-fire': 5}\n",
    "\n",
    "test['label'] = test['label'].replace(mapping)\n",
    "\n",
    "\n",
    "def clean_party(val):\n",
    "    \n",
    "    left = {'democrat', 'green', 'democratic-farmer-labor', 'ocean-state-tea-party-action'}\n",
    "    right = {'republican', 'libertarian', 'tea-party-member', 'Moderate',\n",
    "       'constitution-party'}\n",
    "    \n",
    "    center_none = {'none', 'organization', 'independent',\n",
    "       'columnist', 'activist', 'talk-show-host',\n",
    "       'newsmaker', 'journalist', 'labor-leader', 'state-official',\n",
    "       'business-leader', 'education-official', 'tea-party-member', np.NaN,\n",
    "       'liberal-party-canada', 'government-body', 'Moderate',\n",
    "       }\n",
    "    \n",
    "    if val in left:\n",
    "        return 0\n",
    "    elif val in center_none:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "test['party_affiliation'] = test['party_affiliation'].apply(clean_party)\n",
    "test['subject'] = label_encoder.fit_transform(test['subject'])\n",
    "df['sentiment'] = df['statement'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "668b8a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test_dataset = ClaimDataset(test, tokenizer)  \n",
    "full_test_loader = DataLoader(full_test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c4b52416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.21484375\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.57      0.33       213\n",
      "           1       0.22      0.39      0.28       217\n",
      "           2       0.32      0.04      0.06       196\n",
      "           3       0.08      0.05      0.06       153\n",
      "           4       0.00      0.00      0.00       166\n",
      "           5       0.00      0.00      0.00        79\n",
      "\n",
      "    accuracy                           0.21      1024\n",
      "   macro avg       0.14      0.17      0.12      1024\n",
      "weighted avg       0.17      0.21      0.15      1024\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_statement = batch['input_statement'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        input_political_affiliation = batch['input_political_affiliation'].to(device)\n",
    "        input_subject = batch['input_subject'].to(device)\n",
    "        input_sentiment = batch['input_sentiment'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_statement, attention_mask, input_political_affiliation, \n",
    "                        input_subject, input_sentiment)\n",
    "\n",
    "        # Convert logits to predictions\n",
    "        _, predictions = torch.max(outputs, dim=1)\n",
    "\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate Metrics\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "report = classification_report(all_labels, all_predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad48697c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
